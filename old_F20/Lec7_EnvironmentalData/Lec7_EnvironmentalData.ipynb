{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 7: FAIR data and environmental research\n",
    "ENVR 890-001: Python for Environmental Research, Fall 2020\n",
    "\n",
    "October 9, 2020\n",
    "\n",
    "By Andrew Hamilton. Some material adapted from Matthew Huber & Ashley Dicks (Purdue University).\n",
    "\n",
    "Thanks to Drs. Venkatesh Merwade, Matthew Huber, Carol Song, and Lan Zhao at Purdue University, and the FACT Cyber Training Fellowship (funded under NSF Award #1829764), for training me in FAIR data and science best practices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Summary\n",
    "The use and production of data is fundamental to all research, including environmental science, engineering, and health. Data are stored in a wide variety of formats and locations, from curated online databases to individual spreadsheets to pdf tables. In this lesson, we will learn how to download data from a number of online repositories in order to use in our research. We will also learn about FAIR data standards and best practices for making your own data available to other researchers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Major public environmental data sources\n",
    "1. [USGS National Water Information System](https://waterdata.usgs.gov/nwis)\n",
    "    - Stream flow, water quality, water use, etc.\n",
    "    - Usually easier to search for specific location (e.g., [Bolin Creek](https://waterdata.usgs.gov/nwis/uv?site_no=0209734440))\n",
    "1. [Natural Resources Conservation Service (NRCS)](https://www.wcc.nrcs.usda.gov/snow/)\n",
    "    - Snow depth, water supply forecasts, etc.\n",
    "1. [NOAA National Centers for Environmental Information](https://www.ncdc.noaa.gov/data-access)\n",
    "    - Historical weather data, severe weather database, etc.\n",
    "1. [EPA Air Data](https://www.epa.gov/outdoor-air-quality-data)\n",
    "    - Current & historical air quality data\n",
    "    - Automated plot generation & data downloads\n",
    "1. [EPA Dataset Giveaway](https://edg.epa.gov/metadata/catalog/main/home.page)\n",
    "    - Many different datasets on climate change, locations of Superfund sites, environmental justice, etc.\n",
    "1. [CDC National Center for Environmental Health](https://www.cdc.gov/nceh/data.htm)\n",
    "    - Many datasets about asthma, lead poisoning, nutrition, etc.\n",
    "1. [Organization for Co-operation and Economic Development (OECD) Data](https://data.oecd.org/)\n",
    "    - Country-scale data on environment (air pollution, water withdrawals, CO2 emissions, etc.)\n",
    "    - Energy, healthcare, development, etc.\n",
    "1. [The National Map (USGS)](https://viewer.nationalmap.gov/basic/)\n",
    "    - National Hydrography Dataset\n",
    "    - Digital Elevation Maps\n",
    "    - Place names, transportation networks\n",
    "1. [Multi-Resolution Land Characteristics Consortium (MRLC)](https://www.mrlc.gov/data?f%5B0%5D=category%3Aland%20cover)\n",
    "    - Land use/land cover datasets\n",
    "1. [National Center for Atmospheric Research (NCAR) Research Data Archive](https://rda.ucar.edu/)\n",
    "    - Tons of gridded oceanic & atmospheric datasets & reanalyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4 ways to upload data into Python\n",
    "1. Download csv/xlsx, and use ``pd.read_csv()``, ``pd.read_excel()``\n",
    "\n",
    "1. Copy online table into Excel, then follow #1\n",
    "    - e.g., USGS \"Tab-separated\" output format\n",
    "    \n",
    "1. Using special Python APIs\n",
    "    - [EPA Envirofacts Data Service API](https://www.epa.gov/enviro/web-services)\n",
    "    - These APIs can be pretty tricky to use, and each one will be different. They often require special python packages and/or an account with the provider. But if you need to download a lot of different datasets, or get updated data regularly, it may be worthwhile to figure out.\n",
    "    - [Here](https://techrando.com/2019/07/04/how-to-use-the-environmental-protection-agencys-epas-api-to-pull-data/) is an example of how to use with EPA Envirofacts, but I haven't actually used it.\n",
    "    - [Here](http://kapadia.github.io/usgs/) is a package for interfacing with the USGS API, but I haven't used this either.\n",
    "    \n",
    "1. Query online table directly using url (often the most convenient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use USGS streamflow data from Bolin Creek in Chapel Hill, NC. If you click on the Bolin Creek link above on the USGS website, you will find information about how to download data from this location. One of the options for any query is to get data in csv format, which will open a new browser window with a table of data. For example, [here](https://nwis.waterdata.usgs.gov/nwis/uv?cb_00060=on&cb_00065=on&format=rdb&site_no=0209734440&period=&begin_date=2019-10-02&end_date=2020-10-09). Pandas allows us to access this webpage and access the data directly, rather than having to first save a csv file to our computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "### Use USGS Bolin Creek website to get tab-separated data. Fill in address, header, and delimiter\n",
    "data_address = 'https://nwis.waterdata.usgs.gov/nwis/uv?cb_00060=on&cb_00065=on&format=rdb&site_no=0209734440&period=&begin_date=2019-10-02&end_date=2020-10-09'\n",
    "header = 30\n",
    "delimiter = '\\t'\n",
    "df = pd.read_csv(data_address, header=header, delimiter=delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_cd</th>\n",
       "      <th>site_no</th>\n",
       "      <th>datetime</th>\n",
       "      <th>tz_cd</th>\n",
       "      <th>89527_00065</th>\n",
       "      <th>89527_00065_cd</th>\n",
       "      <th>89528_00060</th>\n",
       "      <th>89528_00060_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USGS</td>\n",
       "      <td>0209734440</td>\n",
       "      <td>2019-10-02 00:00</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1.21</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A:R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USGS</td>\n",
       "      <td>0209734440</td>\n",
       "      <td>2019-10-02 00:15</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1.21</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A:R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USGS</td>\n",
       "      <td>0209734440</td>\n",
       "      <td>2019-10-02 00:30</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1.21</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A:R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USGS</td>\n",
       "      <td>0209734440</td>\n",
       "      <td>2019-10-02 00:45</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1.20</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A:R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USGS</td>\n",
       "      <td>0209734440</td>\n",
       "      <td>2019-10-02 01:00</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1.21</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A:R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35395</th>\n",
       "      <td>USGS</td>\n",
       "      <td>0209734440</td>\n",
       "      <td>2020-10-09 10:15</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1.62</td>\n",
       "      <td>P</td>\n",
       "      <td>1.19</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35396</th>\n",
       "      <td>USGS</td>\n",
       "      <td>0209734440</td>\n",
       "      <td>2020-10-09 10:30</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1.62</td>\n",
       "      <td>P</td>\n",
       "      <td>1.19</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35397</th>\n",
       "      <td>USGS</td>\n",
       "      <td>0209734440</td>\n",
       "      <td>2020-10-09 10:45</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1.61</td>\n",
       "      <td>P</td>\n",
       "      <td>1.10</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35398</th>\n",
       "      <td>USGS</td>\n",
       "      <td>0209734440</td>\n",
       "      <td>2020-10-09 11:00</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1.62</td>\n",
       "      <td>P</td>\n",
       "      <td>1.19</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35399</th>\n",
       "      <td>USGS</td>\n",
       "      <td>0209734440</td>\n",
       "      <td>2020-10-09 11:15</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1.63</td>\n",
       "      <td>P</td>\n",
       "      <td>1.28</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35399 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      agency_cd     site_no          datetime tz_cd 89527_00065  \\\n",
       "1          USGS  0209734440  2019-10-02 00:00   EDT        1.21   \n",
       "2          USGS  0209734440  2019-10-02 00:15   EDT        1.21   \n",
       "3          USGS  0209734440  2019-10-02 00:30   EDT        1.21   \n",
       "4          USGS  0209734440  2019-10-02 00:45   EDT        1.20   \n",
       "5          USGS  0209734440  2019-10-02 01:00   EDT        1.21   \n",
       "...         ...         ...               ...   ...         ...   \n",
       "35395      USGS  0209734440  2020-10-09 10:15   EDT        1.62   \n",
       "35396      USGS  0209734440  2020-10-09 10:30   EDT        1.62   \n",
       "35397      USGS  0209734440  2020-10-09 10:45   EDT        1.61   \n",
       "35398      USGS  0209734440  2020-10-09 11:00   EDT        1.62   \n",
       "35399      USGS  0209734440  2020-10-09 11:15   EDT        1.63   \n",
       "\n",
       "      89527_00065_cd 89528_00060 89528_00060_cd  \n",
       "1                  A        0.00            A:R  \n",
       "2                  A        0.00            A:R  \n",
       "3                  A        0.00            A:R  \n",
       "4                  A        0.00            A:R  \n",
       "5                  A        0.00            A:R  \n",
       "...              ...         ...            ...  \n",
       "35395              P        1.19              P  \n",
       "35396              P        1.19              P  \n",
       "35397              P        1.10              P  \n",
       "35398              P        1.19              P  \n",
       "35399              P        1.28              P  \n",
       "\n",
       "[35399 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[1:, :]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Once you have an example url, you can often figure out how to automatically get data for new dates or locations. For example, how would you change the query to download data from January 1, 2015, to the present?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## To save the data for later, use pandas to_csv()\n",
    "df.to_csv('bolin_creek.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FAIR research\n",
    "<img src=\"stall_fair.PNG\" style=\"width: 400px;\" />(Image cred: Stall, 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**FAIR** data is:\n",
    "- **F**indable: The datasets and resources should be easily located by humans and computers\n",
    "- **A**ccessible: After the dataset is found, the user needs to be able to easily access the datasets\n",
    "- **I**nteroperable: The datasets need to be in a format that is usable by others, therefore needs to satisfy the following \n",
    "- **R**eusable: The datasets need to be able to be used by various people, therefore must have clear metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"wilkinson2016_box2.PNG\" style=\"width: 800px;\" />(Image cred: Wilkinson et al., 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"huber_fair.PNG\" style=\"width: 600px;\" />(Image cred: Matthew Huber et al., [*MyGeoHub*](https://mygeohub.org/cybertraining))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"stall_dataChallenges.PNG\" style=\"width: 800px;\" />(Image cred: Stall, 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"rosenberg2020_fig1.PNG\" style=\"width: 600px;\" />(Image cred: Rosenberg et al., 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"hutton2016_fig1.PNG\" style=\"width: 800px;\" />(Image cred: Hutton et al., 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"stall_dataEcosystem.PNG\" style=\"width: 600px;\" />(Image cred: Stall, 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Coalition for Publishing Data in the Earth and Space Sciences, Enabling FAIR Data Project](https://copdess.org/enabling-fair-data-project/)\n",
    "- Scientific orgs: American Geophysical Union(AGU), European Geosciences Union (AGU), etc.\n",
    "- Publishers: AGU, PNAS, Nature, Science, Elsevier, Wiley, etc.\n",
    "- Repositories & Data Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**More reading on FAIR/open data and science:**\n",
    "- AGU FAIR data working group presentation ([Stall, 2018, Big Data Interagency Working Group](https://www.nitrd.gov/nitrdgroups/images/0/02/Enabling-FAIR-Data-ESES-ShelleyStall.pdf))\n",
    "- FAIR guiding principles for scientific data management and stewardship ([Wilkinson et al, 2020, *Scientific Data*](https://www.nature.com/articles/sdata201618%22))\n",
    "- MyGeoHub description of FAIR principles ([Merwade, Huber, Song, Huang, Zhao, *MyGeoHub*](https://mygeohub.org/cybertraining/fair))\n",
    "- Most computational hydrology is not reproducible, so is it really science? ([Hutton et al., 2016, *Water Resources Research*](https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/2016WR019285))\n",
    "- History, promises, and challenges of open science/open data for public health research ([Huston et al., 2019, *Canada Communicable Disease Report*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6781855/#:~:text=Open%20Data%20is%20based%20on,that%20inform%20and%20support%20them))\n",
    "- Best practices for performing reproducible research, focused on complex computer modeling workflows ([Rosenberg et al., 2020, *Journal of Water Resources Planning and Management*](https://ascelibrary.org/doi/full/10.1061/%28ASCE%29WR.1943-5452.0001215))\n",
    "- Great lecture on how scientists can improve reproducibility/reusability by learning from the open-source software community ([McElreath, 2020, *YouTube*](https://www.youtube.com/watch?v=zwRdO9_GGhY&t=0s&ab_channel=RichardMcElreath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sharing your research products\n",
    "Repositories for sharing research products (data and/or code)\n",
    "1. [HydroShare](https://www.hydroshare.org/landingPage/)\n",
    "1. [Nature Scientific Data list of repositories](https://www.nature.com/sdata/policies/repositories#climate)\n",
    "1. GitHub + Zenodo\n",
    "    - e.g., my [GitHub repository](https://github.com/ahamilton144/hamilton-2020-managing-financial-risk-tradeoffs-for-hydropower) for code associated with a research paper. See \"Tags\" for snapshot versions associated with each submission. Each snapshot is downloadable on Zenodo and has a permanent DOIs. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
